{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2fd10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aca0e138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anagrams',\n",
       " 'anscombe',\n",
       " 'attention',\n",
       " 'brain_networks',\n",
       " 'car_crashes',\n",
       " 'diamonds',\n",
       " 'dots',\n",
       " 'dowjones',\n",
       " 'exercise',\n",
       " 'flights',\n",
       " 'fmri',\n",
       " 'geyser',\n",
       " 'glue',\n",
       " 'healthexp',\n",
       " 'iris',\n",
       " 'mpg',\n",
       " 'penguins',\n",
       " 'planets',\n",
       " 'seaice',\n",
       " 'taxis',\n",
       " 'tips',\n",
       " 'titanic']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.get_dataset_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a786ade0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.343277</td>\n",
       "      <td>-0.421742</td>\n",
       "      <td>-1.737074</td>\n",
       "      <td>-0.030550</td>\n",
       "      <td>1.160377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.649956</td>\n",
       "      <td>-1.051456</td>\n",
       "      <td>0.802359</td>\n",
       "      <td>-0.348997</td>\n",
       "      <td>0.422468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.463006</td>\n",
       "      <td>1.453575</td>\n",
       "      <td>-0.550170</td>\n",
       "      <td>0.538780</td>\n",
       "      <td>-0.853097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.091797</td>\n",
       "      <td>2.009047</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>-0.109336</td>\n",
       "      <td>-1.631164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.711946</td>\n",
       "      <td>-0.257481</td>\n",
       "      <td>0.906049</td>\n",
       "      <td>-1.089839</td>\n",
       "      <td>-0.238052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  1.343277 -0.421742 -1.737074 -0.030550  1.160377\n",
       "1 -0.649956 -1.051456  0.802359 -0.348997  0.422468\n",
       "0  0.463006  1.453575 -0.550170  0.538780 -0.853097\n",
       "0 -0.091797  2.009047  0.178862 -0.109336 -1.631164\n",
       "1 -0.711946 -0.257481  0.906049 -1.089839 -0.238052"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from sklearn.datasets import make_classification\n",
    "x,y=make_classification(random_state=21,n_samples=50,n_features=5,n_classes=2)\n",
    "data=DataFrame(x,y)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b9221ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7176dbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.343277</td>\n",
       "      <td>-0.421742</td>\n",
       "      <td>-1.737074</td>\n",
       "      <td>-0.030550</td>\n",
       "      <td>1.160377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.649956</td>\n",
       "      <td>-1.051456</td>\n",
       "      <td>0.802359</td>\n",
       "      <td>-0.348997</td>\n",
       "      <td>0.422468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.463006</td>\n",
       "      <td>1.453575</td>\n",
       "      <td>-0.550170</td>\n",
       "      <td>0.538780</td>\n",
       "      <td>-0.853097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.091797</td>\n",
       "      <td>2.009047</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>-0.109336</td>\n",
       "      <td>-1.631164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.711946</td>\n",
       "      <td>-0.257481</td>\n",
       "      <td>0.906049</td>\n",
       "      <td>-1.089839</td>\n",
       "      <td>-0.238052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.033409</td>\n",
       "      <td>0.733891</td>\n",
       "      <td>0.065179</td>\n",
       "      <td>-1.155654</td>\n",
       "      <td>-0.595776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.437179</td>\n",
       "      <td>-0.196130</td>\n",
       "      <td>0.555216</td>\n",
       "      <td>-0.349172</td>\n",
       "      <td>-0.116383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.055517</td>\n",
       "      <td>1.825763</td>\n",
       "      <td>1.410349</td>\n",
       "      <td>0.967392</td>\n",
       "      <td>-2.082906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.378199</td>\n",
       "      <td>2.119305</td>\n",
       "      <td>0.549844</td>\n",
       "      <td>1.516635</td>\n",
       "      <td>-1.894508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.258939</td>\n",
       "      <td>-1.492485</td>\n",
       "      <td>-0.377718</td>\n",
       "      <td>-2.067628</td>\n",
       "      <td>1.329603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.313002</td>\n",
       "      <td>-1.992984</td>\n",
       "      <td>0.341235</td>\n",
       "      <td>-0.805068</td>\n",
       "      <td>1.368494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.869367</td>\n",
       "      <td>-0.349918</td>\n",
       "      <td>-1.126570</td>\n",
       "      <td>1.708836</td>\n",
       "      <td>0.811312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.869246</td>\n",
       "      <td>1.013044</td>\n",
       "      <td>-1.085011</td>\n",
       "      <td>1.698377</td>\n",
       "      <td>-0.256890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.130953</td>\n",
       "      <td>-1.645627</td>\n",
       "      <td>1.401729</td>\n",
       "      <td>0.100371</td>\n",
       "      <td>0.590952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.930441</td>\n",
       "      <td>0.810187</td>\n",
       "      <td>-1.169725</td>\n",
       "      <td>-0.124499</td>\n",
       "      <td>-0.060109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.295253</td>\n",
       "      <td>0.276949</td>\n",
       "      <td>-1.654205</td>\n",
       "      <td>0.092408</td>\n",
       "      <td>0.583158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.719110</td>\n",
       "      <td>-1.012375</td>\n",
       "      <td>-0.953820</td>\n",
       "      <td>1.098590</td>\n",
       "      <td>1.237640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.108580</td>\n",
       "      <td>-1.658842</td>\n",
       "      <td>0.088985</td>\n",
       "      <td>1.058969</td>\n",
       "      <td>1.232923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.334187</td>\n",
       "      <td>-0.817145</td>\n",
       "      <td>0.404148</td>\n",
       "      <td>0.575778</td>\n",
       "      <td>0.433923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.443174</td>\n",
       "      <td>-0.786483</td>\n",
       "      <td>1.828601</td>\n",
       "      <td>-1.101122</td>\n",
       "      <td>-0.275230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.822301</td>\n",
       "      <td>3.043289</td>\n",
       "      <td>1.147973</td>\n",
       "      <td>0.480796</td>\n",
       "      <td>-2.892980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.484523</td>\n",
       "      <td>-2.060349</td>\n",
       "      <td>0.559358</td>\n",
       "      <td>-1.247920</td>\n",
       "      <td>1.315322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.599721</td>\n",
       "      <td>-0.466844</td>\n",
       "      <td>0.755635</td>\n",
       "      <td>-1.067961</td>\n",
       "      <td>-0.004646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.629973</td>\n",
       "      <td>-1.430691</td>\n",
       "      <td>2.048811</td>\n",
       "      <td>-1.132255</td>\n",
       "      <td>0.114221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.760968</td>\n",
       "      <td>1.846084</td>\n",
       "      <td>1.032877</td>\n",
       "      <td>-0.383867</td>\n",
       "      <td>-1.916862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.369872</td>\n",
       "      <td>-1.992213</td>\n",
       "      <td>0.414258</td>\n",
       "      <td>-1.006109</td>\n",
       "      <td>1.332756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.095569</td>\n",
       "      <td>2.098982</td>\n",
       "      <td>0.186436</td>\n",
       "      <td>1.076729</td>\n",
       "      <td>-1.703974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181292</td>\n",
       "      <td>-0.339964</td>\n",
       "      <td>-0.243039</td>\n",
       "      <td>0.517998</td>\n",
       "      <td>0.378424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531392</td>\n",
       "      <td>1.314233</td>\n",
       "      <td>-0.642185</td>\n",
       "      <td>3.094482</td>\n",
       "      <td>-0.701650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.961519</td>\n",
       "      <td>-2.555467</td>\n",
       "      <td>1.156601</td>\n",
       "      <td>0.567898</td>\n",
       "      <td>1.408652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.520381</td>\n",
       "      <td>-0.262545</td>\n",
       "      <td>-1.959573</td>\n",
       "      <td>-0.565812</td>\n",
       "      <td>1.145032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027084</td>\n",
       "      <td>1.926939</td>\n",
       "      <td>0.023769</td>\n",
       "      <td>-1.154864</td>\n",
       "      <td>-1.493373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.724860</td>\n",
       "      <td>1.059713</td>\n",
       "      <td>-0.898257</td>\n",
       "      <td>0.687913</td>\n",
       "      <td>-0.382664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.624403</td>\n",
       "      <td>1.265970</td>\n",
       "      <td>-0.763041</td>\n",
       "      <td>0.632968</td>\n",
       "      <td>-0.606366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.215055</td>\n",
       "      <td>-1.492136</td>\n",
       "      <td>-0.321377</td>\n",
       "      <td>-0.707817</td>\n",
       "      <td>1.302218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.718383</td>\n",
       "      <td>-1.025563</td>\n",
       "      <td>-0.953287</td>\n",
       "      <td>-0.567888</td>\n",
       "      <td>1.247526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.811557</td>\n",
       "      <td>-0.765330</td>\n",
       "      <td>1.018486</td>\n",
       "      <td>0.266286</td>\n",
       "      <td>0.098401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.299320</td>\n",
       "      <td>-0.909245</td>\n",
       "      <td>0.356594</td>\n",
       "      <td>-1.201129</td>\n",
       "      <td>0.527640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.271399</td>\n",
       "      <td>0.812763</td>\n",
       "      <td>-0.323685</td>\n",
       "      <td>-0.224142</td>\n",
       "      <td>-0.469278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.058909</td>\n",
       "      <td>1.201586</td>\n",
       "      <td>2.679367</td>\n",
       "      <td>0.162854</td>\n",
       "      <td>-2.213639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.757227</td>\n",
       "      <td>-0.142338</td>\n",
       "      <td>-2.259943</td>\n",
       "      <td>0.297880</td>\n",
       "      <td>1.197149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.379122</td>\n",
       "      <td>-0.557851</td>\n",
       "      <td>0.469704</td>\n",
       "      <td>1.658861</td>\n",
       "      <td>0.202958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.372380</td>\n",
       "      <td>2.429442</td>\n",
       "      <td>0.551797</td>\n",
       "      <td>-0.702969</td>\n",
       "      <td>-2.133962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.822673</td>\n",
       "      <td>-0.959056</td>\n",
       "      <td>-1.085137</td>\n",
       "      <td>-1.783034</td>\n",
       "      <td>1.259835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.835402</td>\n",
       "      <td>-0.739959</td>\n",
       "      <td>1.049864</td>\n",
       "      <td>-0.294332</td>\n",
       "      <td>0.063787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.686424</td>\n",
       "      <td>-0.968631</td>\n",
       "      <td>-0.910535</td>\n",
       "      <td>-0.554801</td>\n",
       "      <td>1.183165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.970302</td>\n",
       "      <td>0.379941</td>\n",
       "      <td>1.257045</td>\n",
       "      <td>0.956813</td>\n",
       "      <td>-0.897198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.532597</td>\n",
       "      <td>1.516973</td>\n",
       "      <td>0.729736</td>\n",
       "      <td>-1.049658</td>\n",
       "      <td>-1.517857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.563799</td>\n",
       "      <td>0.776763</td>\n",
       "      <td>0.747302</td>\n",
       "      <td>-0.126563</td>\n",
       "      <td>-0.957046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.297187</td>\n",
       "      <td>0.014296</td>\n",
       "      <td>2.949159</td>\n",
       "      <td>-1.660613</td>\n",
       "      <td>-1.430389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  1.343277 -0.421742 -1.737074 -0.030550  1.160377\n",
       "1 -0.649956 -1.051456  0.802359 -0.348997  0.422468\n",
       "0  0.463006  1.453575 -0.550170  0.538780 -0.853097\n",
       "0 -0.091797  2.009047  0.178862 -0.109336 -1.631164\n",
       "1 -0.711946 -0.257481  0.906049 -1.089839 -0.238052\n",
       "1 -0.033409  0.733891  0.065179 -1.155654 -0.595776\n",
       "1 -0.437179 -0.196130  0.555216 -0.349172 -0.116383\n",
       "1 -1.055517  1.825763  1.410349  0.967392 -2.082906\n",
       "1 -0.378199  2.119305  0.549844  1.516635 -1.894508\n",
       "0  0.258939 -1.492485 -0.377718 -2.067628  1.329603\n",
       "0 -0.313002 -1.992984  0.341235 -0.805068  1.368494\n",
       "1  0.869367 -0.349918 -1.126570  1.708836  0.811312\n",
       "0  0.869246  1.013044 -1.085011  1.698377 -0.256890\n",
       "1 -1.130953 -1.645627  1.401729  0.100371  0.590952\n",
       "0  0.930441  0.810187 -1.169725 -0.124499 -0.060109\n",
       "0  1.295253  0.276949 -1.654205  0.092408  0.583158\n",
       "0  0.719110 -1.012375 -0.953820  1.098590  1.237640\n",
       "0 -0.108580 -1.658842  0.088985  1.058969  1.232923\n",
       "1 -0.334187 -0.817145  0.404148  0.575778  0.433923\n",
       "1 -1.443174 -0.786483  1.828601 -1.101122 -0.275230\n",
       "0 -0.822301  3.043289  1.147973  0.480796 -2.892980\n",
       "0 -0.484523 -2.060349  0.559358 -1.247920  1.315322\n",
       "1 -0.599721 -0.466844  0.755635 -1.067961 -0.004646\n",
       "1 -1.629973 -1.430691  2.048811 -1.132255  0.114221\n",
       "1 -0.760968  1.846084  1.032877 -0.383867 -1.916862\n",
       "0 -0.369872 -1.992213  0.414258 -1.006109  1.332756\n",
       "0 -0.095569  2.098982  0.186436  1.076729 -1.703974\n",
       "1  0.181292 -0.339964 -0.243039  0.517998  0.378424\n",
       "0  0.531392  1.314233 -0.642185  3.094482 -0.701650\n",
       "1 -0.961519 -2.555467  1.156601  0.567898  1.408652\n",
       "0  1.520381 -0.262545 -1.959573 -0.565812  1.145032\n",
       "0  0.027084  1.926939  0.023769 -1.154864 -1.493373\n",
       "0  0.724860  1.059713 -0.898257  0.687913 -0.382664\n",
       "0  0.624403  1.265970 -0.763041  0.632968 -0.606366\n",
       "0  0.215055 -1.492136 -0.321377 -0.707817  1.302218\n",
       "0  0.718383 -1.025563 -0.953287 -0.567888  1.247526\n",
       "1 -0.811557 -0.765330  1.018486  0.266286  0.098401\n",
       "1 -0.299320 -0.909245  0.356594 -1.201129  0.527640\n",
       "1  0.271399  0.812763 -0.323685 -0.224142 -0.469278\n",
       "1 -2.058909  1.201586  2.679367  0.162854 -2.213639\n",
       "0  1.757227 -0.142338 -2.259943  0.297880  1.197149\n",
       "1 -0.379122 -0.557851  0.469704  1.658861  0.202958\n",
       "0 -0.372380  2.429442  0.551797 -0.702969 -2.133962\n",
       "0  0.822673 -0.959056 -1.085137 -1.783034  1.259835\n",
       "1 -0.835402 -0.739959  1.049864 -0.294332  0.063787\n",
       "0  0.686424 -0.968631 -0.910535 -0.554801  1.183165\n",
       "1 -0.970302  0.379941  1.257045  0.956813 -0.897198\n",
       "1 -0.532597  1.516973  0.729736 -1.049658 -1.517857\n",
       "1 -0.563799  0.776763  0.747302 -0.126563 -0.957046\n",
       "1 -2.297187  0.014296  2.949159 -1.660613 -1.430389"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67ea8340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['a', 'b', 'c', 'd', 'e'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "data.columns=[\"a\",\"b\",\"c\",\"d\",\"e\"]\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6a68052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.343277</td>\n",
       "      <td>-0.421742</td>\n",
       "      <td>-1.737074</td>\n",
       "      <td>-0.030550</td>\n",
       "      <td>1.160377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.649956</td>\n",
       "      <td>-1.051456</td>\n",
       "      <td>0.802359</td>\n",
       "      <td>-0.348997</td>\n",
       "      <td>0.422468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.463006</td>\n",
       "      <td>1.453575</td>\n",
       "      <td>-0.550170</td>\n",
       "      <td>0.538780</td>\n",
       "      <td>-0.853097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.091797</td>\n",
       "      <td>2.009047</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>-0.109336</td>\n",
       "      <td>-1.631164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.711946</td>\n",
       "      <td>-0.257481</td>\n",
       "      <td>0.906049</td>\n",
       "      <td>-1.089839</td>\n",
       "      <td>-0.238052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e\n",
       "0  1.343277 -0.421742 -1.737074 -0.030550  1.160377\n",
       "1 -0.649956 -1.051456  0.802359 -0.348997  0.422468\n",
       "0  0.463006  1.453575 -0.550170  0.538780 -0.853097\n",
       "0 -0.091797  2.009047  0.178862 -0.109336 -1.631164\n",
       "1 -0.711946 -0.257481  0.906049 -1.089839 -0.238052"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87c9ea1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dc4f98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.343277</td>\n",
       "      <td>-0.421742</td>\n",
       "      <td>-1.737074</td>\n",
       "      <td>-0.030550</td>\n",
       "      <td>1.160377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.649956</td>\n",
       "      <td>-1.051456</td>\n",
       "      <td>0.802359</td>\n",
       "      <td>-0.348997</td>\n",
       "      <td>0.422468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.463006</td>\n",
       "      <td>1.453575</td>\n",
       "      <td>-0.550170</td>\n",
       "      <td>0.538780</td>\n",
       "      <td>-0.853097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.091797</td>\n",
       "      <td>2.009047</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>-0.109336</td>\n",
       "      <td>-1.631164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.711946</td>\n",
       "      <td>-0.257481</td>\n",
       "      <td>0.906049</td>\n",
       "      <td>-1.089839</td>\n",
       "      <td>-0.238052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.033409</td>\n",
       "      <td>0.733891</td>\n",
       "      <td>0.065179</td>\n",
       "      <td>-1.155654</td>\n",
       "      <td>-0.595776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.437179</td>\n",
       "      <td>-0.196130</td>\n",
       "      <td>0.555216</td>\n",
       "      <td>-0.349172</td>\n",
       "      <td>-0.116383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.055517</td>\n",
       "      <td>1.825763</td>\n",
       "      <td>1.410349</td>\n",
       "      <td>0.967392</td>\n",
       "      <td>-2.082906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.378199</td>\n",
       "      <td>2.119305</td>\n",
       "      <td>0.549844</td>\n",
       "      <td>1.516635</td>\n",
       "      <td>-1.894508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.258939</td>\n",
       "      <td>-1.492485</td>\n",
       "      <td>-0.377718</td>\n",
       "      <td>-2.067628</td>\n",
       "      <td>1.329603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.313002</td>\n",
       "      <td>-1.992984</td>\n",
       "      <td>0.341235</td>\n",
       "      <td>-0.805068</td>\n",
       "      <td>1.368494</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.869367</td>\n",
       "      <td>-0.349918</td>\n",
       "      <td>-1.126570</td>\n",
       "      <td>1.708836</td>\n",
       "      <td>0.811312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.869246</td>\n",
       "      <td>1.013044</td>\n",
       "      <td>-1.085011</td>\n",
       "      <td>1.698377</td>\n",
       "      <td>-0.256890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.130953</td>\n",
       "      <td>-1.645627</td>\n",
       "      <td>1.401729</td>\n",
       "      <td>0.100371</td>\n",
       "      <td>0.590952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.930441</td>\n",
       "      <td>0.810187</td>\n",
       "      <td>-1.169725</td>\n",
       "      <td>-0.124499</td>\n",
       "      <td>-0.060109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.295253</td>\n",
       "      <td>0.276949</td>\n",
       "      <td>-1.654205</td>\n",
       "      <td>0.092408</td>\n",
       "      <td>0.583158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.719110</td>\n",
       "      <td>-1.012375</td>\n",
       "      <td>-0.953820</td>\n",
       "      <td>1.098590</td>\n",
       "      <td>1.237640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.108580</td>\n",
       "      <td>-1.658842</td>\n",
       "      <td>0.088985</td>\n",
       "      <td>1.058969</td>\n",
       "      <td>1.232923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.334187</td>\n",
       "      <td>-0.817145</td>\n",
       "      <td>0.404148</td>\n",
       "      <td>0.575778</td>\n",
       "      <td>0.433923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.443174</td>\n",
       "      <td>-0.786483</td>\n",
       "      <td>1.828601</td>\n",
       "      <td>-1.101122</td>\n",
       "      <td>-0.275230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.822301</td>\n",
       "      <td>3.043289</td>\n",
       "      <td>1.147973</td>\n",
       "      <td>0.480796</td>\n",
       "      <td>-2.892980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.484523</td>\n",
       "      <td>-2.060349</td>\n",
       "      <td>0.559358</td>\n",
       "      <td>-1.247920</td>\n",
       "      <td>1.315322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.599721</td>\n",
       "      <td>-0.466844</td>\n",
       "      <td>0.755635</td>\n",
       "      <td>-1.067961</td>\n",
       "      <td>-0.004646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.629973</td>\n",
       "      <td>-1.430691</td>\n",
       "      <td>2.048811</td>\n",
       "      <td>-1.132255</td>\n",
       "      <td>0.114221</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.760968</td>\n",
       "      <td>1.846084</td>\n",
       "      <td>1.032877</td>\n",
       "      <td>-0.383867</td>\n",
       "      <td>-1.916862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.369872</td>\n",
       "      <td>-1.992213</td>\n",
       "      <td>0.414258</td>\n",
       "      <td>-1.006109</td>\n",
       "      <td>1.332756</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.095569</td>\n",
       "      <td>2.098982</td>\n",
       "      <td>0.186436</td>\n",
       "      <td>1.076729</td>\n",
       "      <td>-1.703974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181292</td>\n",
       "      <td>-0.339964</td>\n",
       "      <td>-0.243039</td>\n",
       "      <td>0.517998</td>\n",
       "      <td>0.378424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531392</td>\n",
       "      <td>1.314233</td>\n",
       "      <td>-0.642185</td>\n",
       "      <td>3.094482</td>\n",
       "      <td>-0.701650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.961519</td>\n",
       "      <td>-2.555467</td>\n",
       "      <td>1.156601</td>\n",
       "      <td>0.567898</td>\n",
       "      <td>1.408652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.520381</td>\n",
       "      <td>-0.262545</td>\n",
       "      <td>-1.959573</td>\n",
       "      <td>-0.565812</td>\n",
       "      <td>1.145032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027084</td>\n",
       "      <td>1.926939</td>\n",
       "      <td>0.023769</td>\n",
       "      <td>-1.154864</td>\n",
       "      <td>-1.493373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.724860</td>\n",
       "      <td>1.059713</td>\n",
       "      <td>-0.898257</td>\n",
       "      <td>0.687913</td>\n",
       "      <td>-0.382664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.624403</td>\n",
       "      <td>1.265970</td>\n",
       "      <td>-0.763041</td>\n",
       "      <td>0.632968</td>\n",
       "      <td>-0.606366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.215055</td>\n",
       "      <td>-1.492136</td>\n",
       "      <td>-0.321377</td>\n",
       "      <td>-0.707817</td>\n",
       "      <td>1.302218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.718383</td>\n",
       "      <td>-1.025563</td>\n",
       "      <td>-0.953287</td>\n",
       "      <td>-0.567888</td>\n",
       "      <td>1.247526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.811557</td>\n",
       "      <td>-0.765330</td>\n",
       "      <td>1.018486</td>\n",
       "      <td>0.266286</td>\n",
       "      <td>0.098401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.299320</td>\n",
       "      <td>-0.909245</td>\n",
       "      <td>0.356594</td>\n",
       "      <td>-1.201129</td>\n",
       "      <td>0.527640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.271399</td>\n",
       "      <td>0.812763</td>\n",
       "      <td>-0.323685</td>\n",
       "      <td>-0.224142</td>\n",
       "      <td>-0.469278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.058909</td>\n",
       "      <td>1.201586</td>\n",
       "      <td>2.679367</td>\n",
       "      <td>0.162854</td>\n",
       "      <td>-2.213639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.757227</td>\n",
       "      <td>-0.142338</td>\n",
       "      <td>-2.259943</td>\n",
       "      <td>0.297880</td>\n",
       "      <td>1.197149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.379122</td>\n",
       "      <td>-0.557851</td>\n",
       "      <td>0.469704</td>\n",
       "      <td>1.658861</td>\n",
       "      <td>0.202958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.372380</td>\n",
       "      <td>2.429442</td>\n",
       "      <td>0.551797</td>\n",
       "      <td>-0.702969</td>\n",
       "      <td>-2.133962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.822673</td>\n",
       "      <td>-0.959056</td>\n",
       "      <td>-1.085137</td>\n",
       "      <td>-1.783034</td>\n",
       "      <td>1.259835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.835402</td>\n",
       "      <td>-0.739959</td>\n",
       "      <td>1.049864</td>\n",
       "      <td>-0.294332</td>\n",
       "      <td>0.063787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.686424</td>\n",
       "      <td>-0.968631</td>\n",
       "      <td>-0.910535</td>\n",
       "      <td>-0.554801</td>\n",
       "      <td>1.183165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.970302</td>\n",
       "      <td>0.379941</td>\n",
       "      <td>1.257045</td>\n",
       "      <td>0.956813</td>\n",
       "      <td>-0.897198</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.532597</td>\n",
       "      <td>1.516973</td>\n",
       "      <td>0.729736</td>\n",
       "      <td>-1.049658</td>\n",
       "      <td>-1.517857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.563799</td>\n",
       "      <td>0.776763</td>\n",
       "      <td>0.747302</td>\n",
       "      <td>-0.126563</td>\n",
       "      <td>-0.957046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.297187</td>\n",
       "      <td>0.014296</td>\n",
       "      <td>2.949159</td>\n",
       "      <td>-1.660613</td>\n",
       "      <td>-1.430389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e  target\n",
       "0  1.343277 -0.421742 -1.737074 -0.030550  1.160377       0\n",
       "1 -0.649956 -1.051456  0.802359 -0.348997  0.422468       1\n",
       "0  0.463006  1.453575 -0.550170  0.538780 -0.853097       0\n",
       "0 -0.091797  2.009047  0.178862 -0.109336 -1.631164       0\n",
       "1 -0.711946 -0.257481  0.906049 -1.089839 -0.238052       1\n",
       "1 -0.033409  0.733891  0.065179 -1.155654 -0.595776       1\n",
       "1 -0.437179 -0.196130  0.555216 -0.349172 -0.116383       1\n",
       "1 -1.055517  1.825763  1.410349  0.967392 -2.082906       1\n",
       "1 -0.378199  2.119305  0.549844  1.516635 -1.894508       1\n",
       "0  0.258939 -1.492485 -0.377718 -2.067628  1.329603       0\n",
       "0 -0.313002 -1.992984  0.341235 -0.805068  1.368494       0\n",
       "1  0.869367 -0.349918 -1.126570  1.708836  0.811312       1\n",
       "0  0.869246  1.013044 -1.085011  1.698377 -0.256890       0\n",
       "1 -1.130953 -1.645627  1.401729  0.100371  0.590952       1\n",
       "0  0.930441  0.810187 -1.169725 -0.124499 -0.060109       0\n",
       "0  1.295253  0.276949 -1.654205  0.092408  0.583158       0\n",
       "0  0.719110 -1.012375 -0.953820  1.098590  1.237640       0\n",
       "0 -0.108580 -1.658842  0.088985  1.058969  1.232923       0\n",
       "1 -0.334187 -0.817145  0.404148  0.575778  0.433923       1\n",
       "1 -1.443174 -0.786483  1.828601 -1.101122 -0.275230       1\n",
       "0 -0.822301  3.043289  1.147973  0.480796 -2.892980       0\n",
       "0 -0.484523 -2.060349  0.559358 -1.247920  1.315322       0\n",
       "1 -0.599721 -0.466844  0.755635 -1.067961 -0.004646       1\n",
       "1 -1.629973 -1.430691  2.048811 -1.132255  0.114221       1\n",
       "1 -0.760968  1.846084  1.032877 -0.383867 -1.916862       1\n",
       "0 -0.369872 -1.992213  0.414258 -1.006109  1.332756       0\n",
       "0 -0.095569  2.098982  0.186436  1.076729 -1.703974       0\n",
       "1  0.181292 -0.339964 -0.243039  0.517998  0.378424       1\n",
       "0  0.531392  1.314233 -0.642185  3.094482 -0.701650       0\n",
       "1 -0.961519 -2.555467  1.156601  0.567898  1.408652       1\n",
       "0  1.520381 -0.262545 -1.959573 -0.565812  1.145032       0\n",
       "0  0.027084  1.926939  0.023769 -1.154864 -1.493373       0\n",
       "0  0.724860  1.059713 -0.898257  0.687913 -0.382664       0\n",
       "0  0.624403  1.265970 -0.763041  0.632968 -0.606366       0\n",
       "0  0.215055 -1.492136 -0.321377 -0.707817  1.302218       0\n",
       "0  0.718383 -1.025563 -0.953287 -0.567888  1.247526       0\n",
       "1 -0.811557 -0.765330  1.018486  0.266286  0.098401       1\n",
       "1 -0.299320 -0.909245  0.356594 -1.201129  0.527640       1\n",
       "1  0.271399  0.812763 -0.323685 -0.224142 -0.469278       1\n",
       "1 -2.058909  1.201586  2.679367  0.162854 -2.213639       1\n",
       "0  1.757227 -0.142338 -2.259943  0.297880  1.197149       0\n",
       "1 -0.379122 -0.557851  0.469704  1.658861  0.202958       1\n",
       "0 -0.372380  2.429442  0.551797 -0.702969 -2.133962       0\n",
       "0  0.822673 -0.959056 -1.085137 -1.783034  1.259835       0\n",
       "1 -0.835402 -0.739959  1.049864 -0.294332  0.063787       1\n",
       "0  0.686424 -0.968631 -0.910535 -0.554801  1.183165       0\n",
       "1 -0.970302  0.379941  1.257045  0.956813 -0.897198       1\n",
       "1 -0.532597  1.516973  0.729736 -1.049658 -1.517857       1\n",
       "1 -0.563799  0.776763  0.747302 -0.126563 -0.957046       1\n",
       "1 -2.297187  0.014296  2.949159 -1.660613 -1.430389       1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"]=y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3cb7801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.343277</td>\n",
       "      <td>-0.421742</td>\n",
       "      <td>-1.737074</td>\n",
       "      <td>-0.030550</td>\n",
       "      <td>1.160377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.649956</td>\n",
       "      <td>-1.051456</td>\n",
       "      <td>0.802359</td>\n",
       "      <td>-0.348997</td>\n",
       "      <td>0.422468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.463006</td>\n",
       "      <td>1.453575</td>\n",
       "      <td>-0.550170</td>\n",
       "      <td>0.538780</td>\n",
       "      <td>-0.853097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.091797</td>\n",
       "      <td>2.009047</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>-0.109336</td>\n",
       "      <td>-1.631164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.711946</td>\n",
       "      <td>-0.257481</td>\n",
       "      <td>0.906049</td>\n",
       "      <td>-1.089839</td>\n",
       "      <td>-0.238052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e  target\n",
       "0  1.343277 -0.421742 -1.737074 -0.030550  1.160377       0\n",
       "1 -0.649956 -1.051456  0.802359 -0.348997  0.422468       1\n",
       "0  0.463006  1.453575 -0.550170  0.538780 -0.853097       0\n",
       "0 -0.091797  2.009047  0.178862 -0.109336 -1.631164       0\n",
       "1 -0.711946 -0.257481  0.906049 -1.089839 -0.238052       1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index()\n",
    "df.drop(y)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "926e68ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c01c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(\"target\",axis=1)\n",
    "y=df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23f0cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score,mean_absolute_error,mean_squared_error,confusion_matrix,classification_report,roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e77a711b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 5), (10, 5), (40,), (10,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=20,train_size=0.80)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ce76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "[[3 1]\n",
      " [1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.79      0.79      0.79        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logistic model\n",
    "model=LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "y_predict=model.predict(x_test)\n",
    "print(accuracy_score(y_test,y_predict))\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "[[3 1]\n",
      " [1 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.79      0.79      0.79        10\n",
      "weighted avg       0.80      0.80      0.80        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1=LogisticRegressionCV(cv=5)\n",
    "model1.fit(x_train,y_train)\n",
    "y_predict1=model1.predict(x_test)\n",
    "print(accuracy_score(y_test,y_predict1))\n",
    "print(confusion_matrix(y_test,y_predict1))\n",
    "print(classification_report(y_test,y_predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a35b8667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV 1/5] END multi_class=auto, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END multi_class=auto, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=l1, solver=saga;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END multi_class=auto, penalty=l1, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=l1, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=l1, solver=saga;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=l1, solver=saga;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=l2, solver=liblinear;, score=0.875 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END multi_class=auto, penalty=l2, solver=liblinear;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=l2, solver=newton-cg;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=l2, solver=newton-cg;, score=0.875 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END multi_class=auto, penalty=l2, solver=newton-cholesky;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=l2, solver=newton-cholesky;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=l2, solver=newton-cholesky;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=l2, solver=newton-cholesky;, score=0.875 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END multi_class=auto, penalty=l2, solver=newton-cholesky;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=l2, solver=sag;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=l2, solver=sag;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=l2, solver=sag;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=l2, solver=sag;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=l2, solver=sag;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=l2, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=l2, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=l2, solver=saga;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END multi_class=auto, penalty=l2, solver=saga;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=l2, solver=saga;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=auto, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=auto, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=auto, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=auto, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=auto, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=l1, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=l1, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=l1, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=l1, solver=saga;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=l1, solver=saga;, score=0.875 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END multi_class=ovr, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=l2, solver=liblinear;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=l2, solver=liblinear;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=l2, solver=newton-cg;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=l2, solver=newton-cholesky;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=l2, solver=newton-cholesky;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=l2, solver=newton-cholesky;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END multi_class=ovr, penalty=l2, solver=newton-cholesky;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=l2, solver=newton-cholesky;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=l2, solver=sag;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=l2, solver=sag;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=l2, solver=sag;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=l2, solver=sag;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=l2, solver=sag;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=l2, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=l2, solver=saga;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1955: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegressionCV(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END multi_class=ovr, penalty=l2, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=l2, solver=saga;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=l2, solver=saga;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=ovr, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=ovr, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=ovr, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=ovr, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=ovr, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l1, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=l1, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=l1, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l1, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=l1, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=l1, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l1, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=l1, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=l1, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l1, solver=saga;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=l1, solver=saga;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END multi_class=multinomial, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=l2, solver=lbfgs;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l2, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=l2, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END multi_class=multinomial, penalty=l2, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l2, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=l2, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l2, solver=newton-cg;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=l2, solver=newton-cg;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l2, solver=newton-cholesky;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=l2, solver=newton-cholesky;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=l2, solver=newton-cholesky;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l2, solver=newton-cholesky;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=l2, solver=newton-cholesky;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l2, solver=sag;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=l2, solver=sag;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=l2, solver=sag;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l2, solver=sag;, score=0.750 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END multi_class=multinomial, penalty=l2, solver=sag;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=l2, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=l2, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=l2, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=l2, solver=saga;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=l2, solver=saga;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=elasticnet, solver=newton-cholesky;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END multi_class=multinomial, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END multi_class=multinomial, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END multi_class=multinomial, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END multi_class=multinomial, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END multi_class=multinomial, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1936: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "160 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1879, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1879, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1879, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1879, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1879, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1879, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 72, in _check_solver\n",
      "    raise ValueError(\n",
      "        f\"Only 'saga' solver supports elasticnet penalty, got solver={solver}.\"\n",
      "    )\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1879, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1879, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1879, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1894, in fit\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: l1_ratios must be a list of numbers between 0 and 1; got (l1_ratios=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1966, in fit\n",
      "    multi_class = _check_multi_class(multi_class, solver, len(classes))\n",
      "  File \"c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 96, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1135: UserWarning: One or more of the test scores are non-finite: [  nan 0.75    nan   nan   nan 0.8   0.8   0.8   0.8   0.8   0.8   0.8\n",
      "   nan   nan   nan   nan   nan   nan   nan 0.75    nan   nan   nan 0.8\n",
      " 0.8   0.8   0.8   0.8   0.8   0.8     nan   nan   nan   nan   nan   nan\n",
      "   nan   nan   nan   nan   nan 0.8   0.775   nan 0.775 0.775 0.775 0.775\n",
      "   nan   nan   nan   nan   nan   nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1946: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'multi_class': 'auto', 'penalty': 'l1', 'solver': 'saga'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parms={\n",
    "    \"penalty\":[\"l1\",\"l2\",\"elasticnet\"],\n",
    "    \"solver\":[\"lbfgs\",\"liblinear\",\"newton-cg\",\"newton-cholesky\",\"sag\",\"saga\"],\n",
    "    \"multi_class\":[\"auto\",\"ovr\",\"multinomial\"]\n",
    "}\n",
    "grid=GridSearchCV(model1,param_grid=parms,cv=5,verbose=3)\n",
    "grid.fit(x_train,y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "355e6b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multi_class': 'auto', 'penalty': 'l1', 'solver': 'saga'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dac362a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a56b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1fa646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ff06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e8fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3296a3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a5a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e58a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a5845b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4ee952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf5853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e6116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3895b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742b680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b011be90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34c95d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
