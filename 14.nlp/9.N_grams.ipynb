{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbb5c4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpus = [\\n    \"I love machine learning\",\\n    \"I Love nLP\",\\n    \"nlp is better then Machine learning\"\\n]\\ncorpus'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "'''corpus = [\n",
    "    \"I love machine learning\",\n",
    "    \"I Love nLP\",\n",
    "    \"nlp is better then Machine learning\"\n",
    "]\n",
    "corpus'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "172072d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine learning has become one of the most transformative technologies of our time. \\n    It allows computers to learn patterns from data and make predictions without being explicitly programmed. \\n    From healthcare to finance, machine learning is revolutionizing industries and changing the way we interact with technology.',\n",
       " 'Natural Language Processing (NLP) is a specialized branch of artificial intelligence that focuses on enabling machines \\n    to understand, interpret, and generate human language. It powers applications like chatbots, translation systems, and sentiment analysis. \\n    Many researchers argue that NLP is even more impactful than general machine learning because it directly connects machines with human communication.',\n",
       " \"N-gram is a contiguous sequence of 'N' items like words or characters from text or speech. The items can be letters, words or base pairs according to the application. The value of ’N’ determines the order of the N-gram. They are fundamental concept used in various NLP tasks such as language modeling, text classification, machine translation and more.\"]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"\"\"Machine learning has become one of the most transformative technologies of our time. \n",
    "    It allows computers to learn patterns from data and make predictions without being explicitly programmed. \n",
    "    From healthcare to finance, machine learning is revolutionizing industries and changing the way we interact with technology.\"\"\",\n",
    "\n",
    "    \"\"\"Natural Language Processing (NLP) is a specialized branch of artificial intelligence that focuses on enabling machines \n",
    "    to understand, interpret, and generate human language. It powers applications like chatbots, translation systems, and sentiment analysis. \n",
    "    Many researchers argue that NLP is even more impactful than general machine learning because it directly connects machines with human communication.\"\"\",\n",
    "    \n",
    "    \"\"\"N-gram is a contiguous sequence of 'N' items like words or characters from text or speech. The items can be letters, words or base pairs according to the application. The value of ’N’ determines the order of the N-gram. They are fundamental concept used in various NLP tasks such as language modeling, text classification, machine translation and more.\"\"\"\n",
    "]\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d55abd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpuslower=[i.lower() for i in corpus]\\ncorpuslower'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''corpuslower=[i.lower() for i in corpus]\n",
    "corpuslower'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f27be8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prasa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "#stopwords=set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a71a0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#splitting the sentences into words\\nfrom nltk.tokenize import word_tokenize\\nnltk.download('punkt')  \\nwords=[word_tokenize(i) for i in corpuslower]\\nwords\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#splitting the sentences into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')  \n",
    "words=[word_tokenize(i) for i in corpuslower]\n",
    "words'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75a2fb62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#finding unique words\\nunique_words=[]\\nfor i in words:\\n    for word in i:\\n        if word not in stopwords and word not in unique_words:\\n            unique_words.append(word)\\nunique_words'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#finding unique words\n",
    "unique_words=[]\n",
    "for i in words:\n",
    "    for word in i:\n",
    "        if word not in stopwords and word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "unique_words'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f76e200e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in corpus: 153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer() \n",
    "X = vectorizer.fit_transform(corpus) \n",
    "# Total word count across corpus \n",
    "corpus_words = X.sum() \n",
    "print(\"Total number of words in corpus:\", corpus_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "231ae626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0\n",
      "  0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0\n",
      "  1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1 1 1 0]\n",
      " [0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 1 0 0 1 0 0\n",
      "  1 1 0 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 0 0 0 0\n",
      "  0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1\n",
      "  0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 1\n",
      "  0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1]]\n",
      "['according' 'allows' 'analysis' 'and' 'application' 'applications' 'are'\n",
      " 'argue' 'artificial' 'as' 'base' 'be' 'because' 'become' 'being' 'branch'\n",
      " 'can' 'changing' 'characters' 'chatbots' 'classification' 'communication'\n",
      " 'computers' 'concept' 'connects' 'contiguous' 'data' 'determines'\n",
      " 'directly' 'enabling' 'even' 'explicitly' 'finance' 'focuses' 'from'\n",
      " 'fundamental' 'general' 'generate' 'gram' 'has' 'healthcare' 'human'\n",
      " 'impactful' 'in' 'industries' 'intelligence' 'interact' 'interpret' 'is'\n",
      " 'it' 'items' 'language' 'learn' 'learning' 'letters' 'like' 'machine'\n",
      " 'machines' 'make' 'many' 'modeling' 'more' 'most' 'natural' 'nlp' 'of'\n",
      " 'on' 'one' 'or' 'order' 'our' 'pairs' 'patterns' 'powers' 'predictions'\n",
      " 'processing' 'programmed' 'researchers' 'revolutionizing' 'sentiment'\n",
      " 'sequence' 'specialized' 'speech' 'such' 'systems' 'tasks' 'technologies'\n",
      " 'technology' 'text' 'than' 'that' 'the' 'they' 'time' 'to'\n",
      " 'transformative' 'translation' 'understand' 'used' 'value' 'various'\n",
      " 'way' 'we' 'with' 'without' 'words']\n",
      "the total number of words present is: 106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.19346033, 0.17316974],\n",
       "       [0.19346033, 1.        , 0.22733145],\n",
       "       [0.17316974, 0.22733145, 1.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=CountVectorizer(ngram_range=(1,1),binary=True)\n",
    "x=vectorizer.fit_transform(corpus).toarray()\n",
    "print(x)\n",
    "words=vectorizer.get_feature_names_out()\n",
    "print(words)\n",
    "print(\"the total number of words present is:\",len(words))\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec955b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0\n",
      "  0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1\n",
      "  1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 0\n",
      "  1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      "  1 1 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1\n",
      "  1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      "  0 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0]\n",
      " [0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1\n",
      "  0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0\n",
      "  0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 1 0 1 0 1\n",
      "  1 0 1 1 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 1 1\n",
      "  0 0 1 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0\n",
      "  0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      "  1 1 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      "  0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 0\n",
      "  0 0 0 0 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 1 1 1 1 0 1\n",
      "  1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1]]\n",
      "['according' 'according to' 'allows' 'allows computers' 'analysis'\n",
      " 'analysis many' 'and' 'and changing' 'and generate' 'and make' 'and more'\n",
      " 'and sentiment' 'application' 'application the' 'applications'\n",
      " 'applications like' 'are' 'are fundamental' 'argue' 'argue that'\n",
      " 'artificial' 'artificial intelligence' 'as' 'as language' 'base'\n",
      " 'base pairs' 'be' 'be letters' 'because' 'because it' 'become'\n",
      " 'become one' 'being' 'being explicitly' 'branch' 'branch of' 'can'\n",
      " 'can be' 'changing' 'changing the' 'characters' 'characters from'\n",
      " 'chatbots' 'chatbots translation' 'classification'\n",
      " 'classification machine' 'communication' 'computers' 'computers to'\n",
      " 'concept' 'concept used' 'connects' 'connects machines' 'contiguous'\n",
      " 'contiguous sequence' 'data' 'data and' 'determines' 'determines the'\n",
      " 'directly' 'directly connects' 'enabling' 'enabling machines' 'even'\n",
      " 'even more' 'explicitly' 'explicitly programmed' 'finance'\n",
      " 'finance machine' 'focuses' 'focuses on' 'from' 'from data'\n",
      " 'from healthcare' 'from text' 'fundamental' 'fundamental concept'\n",
      " 'general' 'general machine' 'generate' 'generate human' 'gram' 'gram is'\n",
      " 'gram they' 'has' 'has become' 'healthcare' 'healthcare to' 'human'\n",
      " 'human communication' 'human language' 'impactful' 'impactful than' 'in'\n",
      " 'in various' 'industries' 'industries and' 'intelligence'\n",
      " 'intelligence that' 'interact' 'interact with' 'interpret'\n",
      " 'interpret and' 'is' 'is contiguous' 'is even' 'is revolutionizing'\n",
      " 'is specialized' 'it' 'it allows' 'it directly' 'it powers' 'items'\n",
      " 'items can' 'items like' 'language' 'language it' 'language modeling'\n",
      " 'language processing' 'learn' 'learn patterns' 'learning'\n",
      " 'learning because' 'learning has' 'learning is' 'letters' 'letters words'\n",
      " 'like' 'like chatbots' 'like words' 'machine' 'machine learning'\n",
      " 'machine translation' 'machines' 'machines to' 'machines with' 'make'\n",
      " 'make predictions' 'many' 'many researchers' 'modeling' 'modeling text'\n",
      " 'more' 'more impactful' 'most' 'most transformative' 'natural'\n",
      " 'natural language' 'nlp' 'nlp is' 'nlp tasks' 'of' 'of artificial'\n",
      " 'of determines' 'of items' 'of our' 'of the' 'on' 'on enabling' 'one'\n",
      " 'one of' 'or' 'or base' 'or characters' 'or speech' 'order' 'order of'\n",
      " 'our' 'our time' 'pairs' 'pairs according' 'patterns' 'patterns from'\n",
      " 'powers' 'powers applications' 'predictions' 'predictions without'\n",
      " 'processing' 'processing nlp' 'programmed' 'programmed from'\n",
      " 'researchers' 'researchers argue' 'revolutionizing'\n",
      " 'revolutionizing industries' 'sentiment' 'sentiment analysis' 'sequence'\n",
      " 'sequence of' 'specialized' 'specialized branch' 'speech' 'speech the'\n",
      " 'such' 'such as' 'systems' 'systems and' 'tasks' 'tasks such'\n",
      " 'technologies' 'technologies of' 'technology' 'text'\n",
      " 'text classification' 'text or' 'than' 'than general' 'that'\n",
      " 'that focuses' 'that nlp' 'the' 'the application' 'the gram' 'the items'\n",
      " 'the most' 'the order' 'the value' 'the way' 'they' 'they are' 'time'\n",
      " 'time it' 'to' 'to finance' 'to learn' 'to the' 'to understand'\n",
      " 'transformative' 'transformative technologies' 'translation'\n",
      " 'translation and' 'translation systems' 'understand'\n",
      " 'understand interpret' 'used' 'used in' 'value' 'value of' 'various'\n",
      " 'various nlp' 'way' 'way we' 'we' 'we interact' 'with' 'with human'\n",
      " 'with technology' 'without' 'without being' 'words' 'words or']\n",
      "the total number of words present is: 251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.10206207, 0.09072184],\n",
       "       [0.10206207, 1.        , 0.10416667],\n",
       "       [0.09072184, 0.10416667, 1.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer1=CountVectorizer(ngram_range=(1,2),binary=True)\n",
    "x1=vectorizer1.fit_transform(corpus).toarray()\n",
    "print(x1)\n",
    "words1=vectorizer1.get_feature_names_out()\n",
    "print(words1)\n",
    "print(\"the total number of words present is:\",len(words1))\n",
    "cosine_similarity(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "923773d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1\n",
      "  0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0\n",
      "  0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1\n",
      "  0]\n",
      " [0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0\n",
      "  1 0 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0\n",
      "  1 0 1 0 1 1 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0\n",
      "  1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0\n",
      "  0]\n",
      " [1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0\n",
      "  0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      "  0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1\n",
      "  0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 0\n",
      "  1]]\n",
      "['according to' 'allows computers' 'analysis many' 'and changing'\n",
      " 'and generate' 'and make' 'and more' 'and sentiment' 'application the'\n",
      " 'applications like' 'are fundamental' 'argue that'\n",
      " 'artificial intelligence' 'as language' 'base pairs' 'be letters'\n",
      " 'because it' 'become one' 'being explicitly' 'branch of' 'can be'\n",
      " 'changing the' 'characters from' 'chatbots translation'\n",
      " 'classification machine' 'computers to' 'concept used'\n",
      " 'connects machines' 'contiguous sequence' 'data and' 'determines the'\n",
      " 'directly connects' 'enabling machines' 'even more'\n",
      " 'explicitly programmed' 'finance machine' 'focuses on' 'from data'\n",
      " 'from healthcare' 'from text' 'fundamental concept' 'general machine'\n",
      " 'generate human' 'gram is' 'gram they' 'has become' 'healthcare to'\n",
      " 'human communication' 'human language' 'impactful than' 'in various'\n",
      " 'industries and' 'intelligence that' 'interact with' 'interpret and'\n",
      " 'is contiguous' 'is even' 'is revolutionizing' 'is specialized'\n",
      " 'it allows' 'it directly' 'it powers' 'items can' 'items like'\n",
      " 'language it' 'language modeling' 'language processing' 'learn patterns'\n",
      " 'learning because' 'learning has' 'learning is' 'letters words'\n",
      " 'like chatbots' 'like words' 'machine learning' 'machine translation'\n",
      " 'machines to' 'machines with' 'make predictions' 'many researchers'\n",
      " 'modeling text' 'more impactful' 'most transformative' 'natural language'\n",
      " 'nlp is' 'nlp tasks' 'of artificial' 'of determines' 'of items' 'of our'\n",
      " 'of the' 'on enabling' 'one of' 'or base' 'or characters' 'or speech'\n",
      " 'order of' 'our time' 'pairs according' 'patterns from'\n",
      " 'powers applications' 'predictions without' 'processing nlp'\n",
      " 'programmed from' 'researchers argue' 'revolutionizing industries'\n",
      " 'sentiment analysis' 'sequence of' 'specialized branch' 'speech the'\n",
      " 'such as' 'systems and' 'tasks such' 'technologies of'\n",
      " 'text classification' 'text or' 'than general' 'that focuses' 'that nlp'\n",
      " 'the application' 'the gram' 'the items' 'the most' 'the order'\n",
      " 'the value' 'the way' 'they are' 'time it' 'to finance' 'to learn'\n",
      " 'to the' 'to understand' 'transformative technologies' 'translation and'\n",
      " 'translation systems' 'understand interpret' 'used in' 'value of'\n",
      " 'various nlp' 'way we' 'we interact' 'with human' 'with technology'\n",
      " 'without being' 'words or']\n",
      "the total number of words present is: 145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.02135407, 0.02094729],\n",
       "       [0.02135407, 1.        , 0.        ],\n",
       "       [0.02094729, 0.        , 1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2=CountVectorizer(ngram_range=(2,2),binary=True)\n",
    "x2=vectorizer2.fit_transform(corpus).toarray()\n",
    "print(x2)\n",
    "words2=vectorizer2.get_feature_names_out()\n",
    "print(words2)\n",
    "print(\"the total number of words present is:\",len(words2))\n",
    "cosine_similarity(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e239ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
      "  1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0\n",
      "  0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 0 1\n",
      "  0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 1 0\n",
      "  1 0 0]\n",
      " [0 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 1\n",
      "  0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0\n",
      "  1 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0\n",
      "  1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1\n",
      "  0 0 0]\n",
      " [1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0\n",
      "  0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1\n",
      "  0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      "  0 1 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0\n",
      "  0 1 1]]\n",
      "['according to the' 'allows computers to' 'analysis many researchers'\n",
      " 'and changing the' 'and generate human' 'and make predictions'\n",
      " 'and sentiment analysis' 'application the value'\n",
      " 'applications like chatbots' 'are fundamental concept' 'argue that nlp'\n",
      " 'artificial intelligence that' 'as language modeling'\n",
      " 'base pairs according' 'be letters words' 'because it directly'\n",
      " 'become one of' 'being explicitly programmed' 'branch of artificial'\n",
      " 'can be letters' 'changing the way' 'characters from text'\n",
      " 'chatbots translation systems' 'classification machine translation'\n",
      " 'computers to learn' 'concept used in' 'connects machines with'\n",
      " 'contiguous sequence of' 'data and make' 'determines the order'\n",
      " 'directly connects machines' 'enabling machines to' 'even more impactful'\n",
      " 'explicitly programmed from' 'finance machine learning'\n",
      " 'focuses on enabling' 'from data and' 'from healthcare to' 'from text or'\n",
      " 'fundamental concept used' 'general machine learning'\n",
      " 'generate human language' 'gram is contiguous' 'gram they are'\n",
      " 'has become one' 'healthcare to finance' 'human language it'\n",
      " 'impactful than general' 'in various nlp' 'industries and changing'\n",
      " 'intelligence that focuses' 'interact with technology'\n",
      " 'interpret and generate' 'is contiguous sequence' 'is even more'\n",
      " 'is revolutionizing industries' 'is specialized branch'\n",
      " 'it allows computers' 'it directly connects' 'it powers applications'\n",
      " 'items can be' 'items like words' 'language it powers'\n",
      " 'language modeling text' 'language processing nlp' 'learn patterns from'\n",
      " 'learning because it' 'learning has become' 'learning is revolutionizing'\n",
      " 'letters words or' 'like chatbots translation' 'like words or'\n",
      " 'machine learning because' 'machine learning has' 'machine learning is'\n",
      " 'machine translation and' 'machines to understand' 'machines with human'\n",
      " 'make predictions without' 'many researchers argue'\n",
      " 'modeling text classification' 'more impactful than'\n",
      " 'most transformative technologies' 'natural language processing'\n",
      " 'nlp is even' 'nlp is specialized' 'nlp tasks such'\n",
      " 'of artificial intelligence' 'of determines the' 'of items like'\n",
      " 'of our time' 'of the gram' 'of the most' 'on enabling machines'\n",
      " 'one of the' 'or base pairs' 'or characters from' 'or speech the'\n",
      " 'order of the' 'our time it' 'pairs according to' 'patterns from data'\n",
      " 'powers applications like' 'predictions without being'\n",
      " 'processing nlp is' 'programmed from healthcare' 'researchers argue that'\n",
      " 'revolutionizing industries and' 'sentiment analysis many'\n",
      " 'sequence of items' 'specialized branch of' 'speech the items'\n",
      " 'such as language' 'systems and sentiment' 'tasks such as'\n",
      " 'technologies of our' 'text classification machine' 'text or speech'\n",
      " 'than general machine' 'that focuses on' 'that nlp is'\n",
      " 'the application the' 'the gram they' 'the items can'\n",
      " 'the most transformative' 'the order of' 'the value of' 'the way we'\n",
      " 'they are fundamental' 'time it allows' 'to finance machine'\n",
      " 'to learn patterns' 'to the application' 'to understand interpret'\n",
      " 'transformative technologies of' 'translation and more'\n",
      " 'translation systems and' 'understand interpret and' 'used in various'\n",
      " 'value of determines' 'various nlp tasks' 'way we interact'\n",
      " 'we interact with' 'with human communication' 'without being explicitly'\n",
      " 'words or base' 'words or characters']\n",
      "the total number of words present is: 147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer3=CountVectorizer(ngram_range=(3,3),binary=True)\n",
    "x3=vectorizer3.fit_transform(corpus).toarray()\n",
    "print(x3)\n",
    "words3=vectorizer3.get_feature_names_out()\n",
    "print(words3)\n",
    "print(\"the total number of words present is:\",len(words3))\n",
    "cosine_similarity(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48ce5d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      "  1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0\n",
      "  0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0\n",
      "  0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0\n",
      "  0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      "  1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1\n",
      "  1 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0\n",
      "  0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1\n",
      "  1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1\n",
      "  0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1\n",
      "  0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0\n",
      "  0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1\n",
      "  0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      "  0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0\n",
      "  0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      "  1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      "  1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1 0\n",
      "  0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1\n",
      "  0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      "  0 1 1 1]]\n",
      "['according to' 'according to the' 'allows computers'\n",
      " 'allows computers to' 'analysis many' 'analysis many researchers'\n",
      " 'and changing' 'and changing the' 'and generate' 'and generate human'\n",
      " 'and make' 'and make predictions' 'and more' 'and sentiment'\n",
      " 'and sentiment analysis' 'application the' 'application the value'\n",
      " 'applications like' 'applications like chatbots' 'are fundamental'\n",
      " 'are fundamental concept' 'argue that' 'argue that nlp'\n",
      " 'artificial intelligence' 'artificial intelligence that' 'as language'\n",
      " 'as language modeling' 'base pairs' 'base pairs according' 'be letters'\n",
      " 'be letters words' 'because it' 'because it directly' 'become one'\n",
      " 'become one of' 'being explicitly' 'being explicitly programmed'\n",
      " 'branch of' 'branch of artificial' 'can be' 'can be letters'\n",
      " 'changing the' 'changing the way' 'characters from'\n",
      " 'characters from text' 'chatbots translation'\n",
      " 'chatbots translation systems' 'classification machine'\n",
      " 'classification machine translation' 'computers to' 'computers to learn'\n",
      " 'concept used' 'concept used in' 'connects machines'\n",
      " 'connects machines with' 'contiguous sequence' 'contiguous sequence of'\n",
      " 'data and' 'data and make' 'determines the' 'determines the order'\n",
      " 'directly connects' 'directly connects machines' 'enabling machines'\n",
      " 'enabling machines to' 'even more' 'even more impactful'\n",
      " 'explicitly programmed' 'explicitly programmed from' 'finance machine'\n",
      " 'finance machine learning' 'focuses on' 'focuses on enabling' 'from data'\n",
      " 'from data and' 'from healthcare' 'from healthcare to' 'from text'\n",
      " 'from text or' 'fundamental concept' 'fundamental concept used'\n",
      " 'general machine' 'general machine learning' 'generate human'\n",
      " 'generate human language' 'gram is' 'gram is contiguous' 'gram they'\n",
      " 'gram they are' 'has become' 'has become one' 'healthcare to'\n",
      " 'healthcare to finance' 'human communication' 'human language'\n",
      " 'human language it' 'impactful than' 'impactful than general'\n",
      " 'in various' 'in various nlp' 'industries and' 'industries and changing'\n",
      " 'intelligence that' 'intelligence that focuses' 'interact with'\n",
      " 'interact with technology' 'interpret and' 'interpret and generate'\n",
      " 'is contiguous' 'is contiguous sequence' 'is even' 'is even more'\n",
      " 'is revolutionizing' 'is revolutionizing industries' 'is specialized'\n",
      " 'is specialized branch' 'it allows' 'it allows computers' 'it directly'\n",
      " 'it directly connects' 'it powers' 'it powers applications' 'items can'\n",
      " 'items can be' 'items like' 'items like words' 'language it'\n",
      " 'language it powers' 'language modeling' 'language modeling text'\n",
      " 'language processing' 'language processing nlp' 'learn patterns'\n",
      " 'learn patterns from' 'learning because' 'learning because it'\n",
      " 'learning has' 'learning has become' 'learning is'\n",
      " 'learning is revolutionizing' 'letters words' 'letters words or'\n",
      " 'like chatbots' 'like chatbots translation' 'like words' 'like words or'\n",
      " 'machine learning' 'machine learning because' 'machine learning has'\n",
      " 'machine learning is' 'machine translation' 'machine translation and'\n",
      " 'machines to' 'machines to understand' 'machines with'\n",
      " 'machines with human' 'make predictions' 'make predictions without'\n",
      " 'many researchers' 'many researchers argue' 'modeling text'\n",
      " 'modeling text classification' 'more impactful' 'more impactful than'\n",
      " 'most transformative' 'most transformative technologies'\n",
      " 'natural language' 'natural language processing' 'nlp is' 'nlp is even'\n",
      " 'nlp is specialized' 'nlp tasks' 'nlp tasks such' 'of artificial'\n",
      " 'of artificial intelligence' 'of determines' 'of determines the'\n",
      " 'of items' 'of items like' 'of our' 'of our time' 'of the' 'of the gram'\n",
      " 'of the most' 'on enabling' 'on enabling machines' 'one of' 'one of the'\n",
      " 'or base' 'or base pairs' 'or characters' 'or characters from'\n",
      " 'or speech' 'or speech the' 'order of' 'order of the' 'our time'\n",
      " 'our time it' 'pairs according' 'pairs according to' 'patterns from'\n",
      " 'patterns from data' 'powers applications' 'powers applications like'\n",
      " 'predictions without' 'predictions without being' 'processing nlp'\n",
      " 'processing nlp is' 'programmed from' 'programmed from healthcare'\n",
      " 'researchers argue' 'researchers argue that' 'revolutionizing industries'\n",
      " 'revolutionizing industries and' 'sentiment analysis'\n",
      " 'sentiment analysis many' 'sequence of' 'sequence of items'\n",
      " 'specialized branch' 'specialized branch of' 'speech the'\n",
      " 'speech the items' 'such as' 'such as language' 'systems and'\n",
      " 'systems and sentiment' 'tasks such' 'tasks such as' 'technologies of'\n",
      " 'technologies of our' 'text classification' 'text classification machine'\n",
      " 'text or' 'text or speech' 'than general' 'than general machine'\n",
      " 'that focuses' 'that focuses on' 'that nlp' 'that nlp is'\n",
      " 'the application' 'the application the' 'the gram' 'the gram they'\n",
      " 'the items' 'the items can' 'the most' 'the most transformative'\n",
      " 'the order' 'the order of' 'the value' 'the value of' 'the way'\n",
      " 'the way we' 'they are' 'they are fundamental' 'time it' 'time it allows'\n",
      " 'to finance' 'to finance machine' 'to learn' 'to learn patterns' 'to the'\n",
      " 'to the application' 'to understand' 'to understand interpret'\n",
      " 'transformative technologies' 'transformative technologies of'\n",
      " 'translation and' 'translation and more' 'translation systems'\n",
      " 'translation systems and' 'understand interpret'\n",
      " 'understand interpret and' 'used in' 'used in various' 'value of'\n",
      " 'value of determines' 'various nlp' 'various nlp tasks' 'way we'\n",
      " 'way we interact' 'we interact' 'we interact with' 'with human'\n",
      " 'with human communication' 'with technology' 'without being'\n",
      " 'without being explicitly' 'words or' 'words or base'\n",
      " 'words or characters']\n",
      "the total number of words present is: 292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.01067704, 0.01047364],\n",
       "       [0.01067704, 1.        , 0.        ],\n",
       "       [0.01047364, 0.        , 1.        ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer4=CountVectorizer(ngram_range=(2,3),binary=True)\n",
    "x4=vectorizer4.fit_transform(corpus).toarray()\n",
    "print(x4)\n",
    "words4=vectorizer4.get_feature_names_out()\n",
    "print(words4)\n",
    "print(\"the total number of words present is:\",len(words4))\n",
    "cosine_similarity(x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c89937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial words in corpus: 153\n",
      "no.of words when ngramrange=(1,1): 106\n",
      "no.of words when ngramrange=(1,2): 251\n",
      "no.of words when ngramrange=(2,2): 145\n",
      "no.of words when ngramrange=(3,3): 147\n",
      "no.of words when ngramrange=(2,3): 292\n"
     ]
    }
   ],
   "source": [
    "print(\"initial words in corpus:\", corpus_words)                     # initial words in corpus\n",
    "print(\"no.of words when ngramrange=(1,1):\",len(words))              #(1,1)\n",
    "print(\"no.of words when ngramrange=(1,2):\",len(words1))             #(1,2)\n",
    "print(\"no.of words when ngramrange=(2,2):\",len(words2))             #(2,2)\n",
    "print(\"no.of words when ngramrange=(3,3):\",len(words3))             #(3,3)\n",
    "print(\"no.of words when ngramrange=(2,3):\",len(words4))             #(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ca38f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_similarity when ngramrange=(1,1):\n",
      " [[1.         0.19346033 0.17316974]\n",
      " [0.19346033 1.         0.22733145]\n",
      " [0.17316974 0.22733145 1.        ]]\n",
      "cosine_similarity when ngramrange=(1,2):\n",
      " [[1.         0.10206207 0.09072184]\n",
      " [0.10206207 1.         0.10416667]\n",
      " [0.09072184 0.10416667 1.        ]]\n",
      "cosine_similarity when ngramrange=(2,2):\n",
      " [[1.         0.02135407 0.02094729]\n",
      " [0.02135407 1.         0.        ]\n",
      " [0.02094729 0.         1.        ]]\n",
      "cosine_similarity when ngramrange=(3,3):\n",
      " [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "cosine_similarity when ngramrange=(2,3):\n",
      " [[1.         0.01067704 0.01047364]\n",
      " [0.01067704 1.         0.        ]\n",
      " [0.01047364 0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"cosine_similarity when ngramrange=(1,1):\\n\",cosine_similarity(x))      #(1,1)\n",
    "print(\"cosine_similarity when ngramrange=(1,2):\\n\",cosine_similarity(x1))     #(1,2)\n",
    "print(\"cosine_similarity when ngramrange=(2,2):\\n\",cosine_similarity(x2))     #(2,2)\n",
    "print(\"cosine_similarity when ngramrange=(3,3):\\n\",cosine_similarity(x3))     #(3,3)\n",
    "print(\"cosine_similarity when ngramrange=(2,3):\\n\",cosine_similarity(x4))     #(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387f044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
