{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7912d987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "corpus = [\n",
    "    \"I love machine learning\",\n",
    "    \"I Love nLP\",\n",
    "    \"nlp is better then Machine learning\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1446ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce150ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[i.lower() for i in corpus]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2count = {}\n",
    "for data in dataset:\n",
    "    words = nltk.word_tokenize(data)\n",
    "    for word in words:\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "word2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15fea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319948dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out stopwords\n",
    "filtered_word2count = {word: count for word, count in word2count.items() if word.lower() not in stop_words}\n",
    "\n",
    "filtered_word2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a5ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "word_freq_df = pd.DataFrame(list(filtered_word2count.items()), columns=['Word', 'Frequency'])\n",
    "word_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a4c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words = word_freq_df['Word'].tolist()\n",
    "freq_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180bdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= []\n",
    "for data in corpus:\n",
    "    vector = []\n",
    "    tokens = nltk.word_tokenize(data.lower()) \n",
    "    for word in freq_words:\n",
    "        if word in tokens:\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            vector.append(0)\n",
    "    x.append(vector)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646976e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.asarray(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf56f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    x,\n",
    "    annot=True,\n",
    "    xticklabels=freq_words,\n",
    ")\n",
    "\n",
    "plt.title('Bag of Words Matrix')\n",
    "plt.xlabel('Frequent Words')\n",
    "plt.ylabel('Sentences')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667fddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b3b7691",
   "metadata": {},
   "source": [
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4423affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus)\n",
    "corpus=[i.lower() for i in corpus]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c320a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with our removing the stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer()   \n",
    "x=cv.fit_transform(corpus).toarray()\n",
    "print(x)\n",
    "words = cv.get_feature_names_out()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(x,annot=True,xticklabels=words,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df248b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after removing the stop words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(stop_words='english')   \n",
    "x=cv.fit_transform(corpus).toarray()\n",
    "print(x)\n",
    "words1 = cv.get_feature_names_out()\n",
    "print(words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d077a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(x,annot=True,xticklabels=words1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
