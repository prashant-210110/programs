{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ec8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "#api keys and set up environment\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"AIzaSyBOgqZAxIBdR6PbP1FYj7kUL6n2V1IZVwg\" \n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5060e549",
   "metadata": {},
   "source": [
    "using sql databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1043b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prasa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(profile={'max_input_tokens': 1048576, 'max_output_tokens': 65536, 'image_inputs': True, 'audio_inputs': True, 'pdf_inputs': True, 'video_inputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'image_tool_message': True, 'tool_choice': True}, google_api_key=SecretStr('**********'), model='gemini-2.5-flash-lite', client=<google.genai.client.Client object at 0x00000237E90FABA0>, default_metadata=(), model_kwargs={})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBOgqZAxIBdR6PbP1FYj7kUL6n2V1IZVwg\"\n",
    "#model building\n",
    "model = init_chat_model(\"google_genai:gemini-2.5-flash-lite\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fddb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogleGenerativeAIEmbeddings(client=<google.genai.client.Client object at 0x00000237E91ADBD0>, model='models/gemini-embedding-001', task_type=None, google_api_key=SecretStr('**********'), credentials=None, vertexai=None, project=None, location=None, base_url=None, additional_headers=None, client_args=None, request_options=None, output_dimensionality=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "#embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e68a60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_core.vectorstores.in_memory.InMemoryVectorStore at 0x237e92a96a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#storing in vector databases\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b2e792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in c:\\users\\prasa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (9.5.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Database connection parameters\n",
    "config = {\n",
    "    'user': 'root',\n",
    "    'password': '',\n",
    "    'host': '127.0.0.1',\n",
    "    'database': 'project_gemini'\n",
    "}\n",
    "\n",
    "# Connect\n",
    "conn = mysql.connector.connect(**config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Run query\n",
    "query = \"SELECT * FROM sample_transactions\"\n",
    "cursor.execute(query)\n",
    "\n",
    "# Get column names\n",
    "columns = [desc[0] for desc in cursor.description]\n",
    "\n",
    "# Fetch all rows\n",
    "rows = cursor.fetchall()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9359b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs = []\n",
    "for idx, row in enumerate(rows):\n",
    "    # Build a readable text string from the row\n",
    "    text = \", \".join(f\"{col}: {val}\" for col, val in zip(columns, row))\n",
    "    \n",
    "    # Create Document\n",
    "    doc = Document(\n",
    "        page_content=text,\n",
    "        metadata={\"row_index\": idx, \"table\": \"sample_transactions\"}\n",
    "    )\n",
    "    docs.append(doc)\n",
    "\n",
    "print(f\"Loaded {len(docs)} documents\")\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#connecting the sql to our model\n",
    "from email import header\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "# Database connection parameters (default XAMPP credentials)\n",
    "config = {\n",
    "    'user': 'root',\n",
    "    'password': '',\n",
    "    'host': '127.0.0.1',\n",
    "    'database': 'project_gemini' \n",
    "}\n",
    "\n",
    "# Connect to the database\n",
    "conn = mysql.connector.connect(**config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Extract data from a specific table \n",
    "query = \"SELECT * FROM sample_transactions\"\n",
    "loader = pd.read_sql(query, conn)\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "df.head()\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Convert DataFrame rows into Document objects\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=f\"Customer: {row['COL 1']}, \"\n",
    "                     f\"Account: {row['COL 2']}, \"\n",
    "                     f\"Phone: {row['COL 3']}, \"\n",
    "                     f\"Date: {row['COL 4']}, \"\n",
    "                     f\"Amount: {row['COL 5']}\",\n",
    "        metadata={\"row_index\": idx}\n",
    "    )\n",
    "    for idx, row in df.iterrows()\n",
    "]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010b450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split into {len(all_splits)} sub-documents.\")\n",
    "print(all_splits[0].page_content[:200])  # preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff27927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the documents\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fb3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect Gemini\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure retriever from your vector DB\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be8078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secure system prompt\n",
    "policy_prompt = \"\"\"\n",
    "You are a secure assistant working with sensitive financial data.\n",
    "RULES:\n",
    "- Never reveal full account numbers, phone numbers, exact balances, salaries, or credit scores.\n",
    "- Always mask sensitive values (e.g., XXXX9012 for account numbers).\n",
    "- For balances or amounts, provide ranges or summaries instead of exact values.\n",
    "- If asked directly for restricted data, politely refuse and explain the restriction.\n",
    "- Always offer a safe alternative (aggregated insights, summaries, masked values).\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=policy_prompt + \"\\n\\nContext: {context}\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fcabfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build RetrievalQA chain (not BaseRetriever!)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=model,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries\n",
    "print(qa_chain.run(\"Show me the customer's account number.\"))\n",
    "print(qa_chain.run(\"What is the average transaction amount?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d84e02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d1709e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611b999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa679d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
